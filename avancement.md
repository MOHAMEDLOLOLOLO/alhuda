#Ã©tat d'avancement :Obstacle Detection AI

## ğŸ¯ Objectif
DÃ©velopper un prototype de **lunettes intelligentes** capables de dÃ©tecter les obstacles lors de la marche,
grÃ¢ce Ã  une camÃ©ra embarquÃ©e et un traitement IA dÃ©portÃ© sur PC.

## ğŸ§© Architecture actuelle
- **CamÃ©ra** : module camÃ©ra du Raspberry Pi Zero 2 W.
- **Transmission** : flux vidÃ©o H.264 envoyÃ© via UDP (`udpsink`) au PC.
- **Traitement IA** : sur PC, en Python avec PyTorch / OpenCV.
- **Affichage** : annotation en direct (`Obstacle` / `Pas obstacle`).
- **Communication retour** (prÃ©vu) : envoi dâ€™alerte UDP vers le Pi pour retour haptique ou sonore.

---

## âš™ï¸ Ã‰tapes dÃ©jÃ  rÃ©alisÃ©es

### ğŸ§  1. Prototype de classification binaire 1
- ModÃ¨le utilisÃ© : **MobileNetV3-Small (prÃ©-entraÃ®nÃ© ImageNet)**.
- AdaptÃ© Ã  **2 classes** : `Obstacle` / `Pas obstacle`.
- InfÃ©rence directe sur les frames du flux UDP (FFmpeg ou GStreamer).
- Pipeline vidÃ©o :
  ```bash
  Raspberry â†’ UDP â†’ PC â†’ MobileNetV3 â†’ Affichage + DÃ©tection

tester:
//editer la connection plus avec wpa.coonf mais avec sudo nmtui

Sur le Raspberry Pi â€” Ã‰mission du flux vidÃ©o

Lance la commande suivante :
rpicam-vid -t 0 \
  --width 640 --height 480 --framerate 30 \
  --codec h264 --inline --listen \
  -o udp://<IP_PC>:5000
  
Sur le PC â€” RÃ©ception et traitement IA

CrÃ©e un fichier obstacle_simple.py
lancer obstacle_simple.py

rÃ©sultat:
<img width="1451" height="1091" alt="Capture d'Ã©cran 2025-10-28 163614" src="https://github.com/user-attachments/assets/a9e77bf0-5f01-4b2a-97fd-ebc2c7a40e20" />
<img width="1368" height="1113" alt="Capture d'Ã©cran 2025-10-28 163652" src="https://github.com/user-attachments/assets/4393ffc7-d95a-4c0a-b961-0075d14f52a6" />

SUITE 

ğŸš€ 2. DÃ©tection dâ€™obstacles par localisation (YOLOv8 + SafeWalkBD)
ğŸ” Objectif de cette Ã©tape

AmÃ©liorer la prÃ©cision et la pertinence de la dÃ©tection en remplaÃ§ant la simple classification binaire (Obstacle / Pas obstacle) par une dÃ©tection dâ€™objets.
Lâ€™objectif est dâ€™identifier les obstacles visibles et de dÃ©terminer sâ€™ils se trouvent rÃ©ellement sur la trajectoire de marche (zone centrale de lâ€™image).

ğŸ§  ModÃ¨le utilisÃ©

ModÃ¨le : YOLOv8 (Ultralytics)

Dataset : SafeWalkBD (hÃ©bergÃ© sur Roboflow Universe
)

Poids : best.pt (version YOLOv8, tÃ©lÃ©chargÃ©e automatiquement depuis Roboflow)

Langage : Python 3.10+

Librairies principales :

ultralytics â†’ pour le modÃ¨le YOLOv8

opencv-python â†’ pour le flux vidÃ©o et lâ€™affichage

roboflow â†’ pour le tÃ©lÃ©chargement automatique du modÃ¨le

âš™ï¸ Fonctionnement actuel

Le PC reÃ§oit en temps rÃ©el le flux vidÃ©o du Raspberry Pi (H.264 / UDP) et applique le modÃ¨le YOLOv8.
Chaque objet dÃ©tectÃ© est analysÃ© pour vÃ©rifier sâ€™il se trouve dans une zone centrale basse de lâ€™image â€” correspondant Ã  la direction de marche de lâ€™utilisateur.

Si un objet est dÃ©tectÃ© dans cette zone :
â¡ï¸ OBSTACLE
Sinon :
â¡ï¸ LIBRE


code dans obstacle_yolov8_centre.py

entrainement avec ce datasets https://universe.roboflow.com/tfg-7qtpm/accesibility-street/dataset/11/images

Jâ€™ai effectuÃ© de nombreuses recherches de datasets en ligne et entraÃ®nÃ© plusieurs modÃ¨les.
Cependant, les rÃ©sultats, bien que fonctionnels, manquaient souvent de prÃ©cision.
Jâ€™ai constatÃ© que le problÃ¨me venait principalement des labels : les annotations des images nâ€™Ã©taient pas toujours adaptÃ©es Ã  mon cas dâ€™usage.

Ã€ partir de ce constat, jâ€™ai eu lâ€™idÃ©e de dÃ©velopper un outil de relabellisation dâ€™images.
Cet outil permet dâ€™afficher une image et son ancien label, puis de sÃ©lectionner un nouveau label parmi une liste de catÃ©gories adaptÃ©es Ã  mon projet.
Une fois la sÃ©lection faite, le programme met automatiquement Ã  jour le fichier de labels associÃ© Ã  lâ€™image.

Lâ€™objectif est dâ€™affiner les annotations pour constituer un dataset beaucoup plus pertinent, afin dâ€™entraÃ®ner un modÃ¨le mieux adaptÃ© Ã  la dÃ©tection dâ€™obstacles et dâ€™Ã©lÃ©ments utiles Ã  la navigation pour les personnes aveugles.

<img width="2118" height="1123" alt="image" src="https://github.com/user-attachments/assets/991b5cfc-d4d7-43e1-ad94-0b0000a7fb1a" />


changement de datasets 
â”œâ”€â”€ person/

â”œâ”€â”€ vehicle/

â”œâ”€â”€ stairs/

â”œâ”€â”€ crosswalk/

â”œâ”€â”€ sidewalk/

â”œâ”€â”€ pothole/

â”œâ”€â”€ ramp/

â”œâ”€â”€ obstacle/

â”œâ”€â”€ garbage/

â””â”€â”€ tree/

Type de classe	                                                                                        	   QuantitÃ©

FrÃ©quente (ex : person, vehicle, sidewalk)	souvent visibles	2000â€“4000 images

Moyenne (ex : stairs, crosswalk, obstacle)	parfois visibles	1000â€“2000 images

Rare / SpÃ©cifique (ex : pothole, ramp, garbage)	peu prÃ©sentes	700â€“1500 images

